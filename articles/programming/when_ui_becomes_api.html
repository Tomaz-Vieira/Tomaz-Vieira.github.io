<!doctype html>

<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ramblings</title>
  <!-- <link rel="icon" href="/images/favicon.png"> -->
</head>

<body>
    <h1>When UI becomes API</h1>

    <p>
        “Things that are made for humans” (UI) and “things that are made for machines” (API) have fundamentally opposite goals and requirements, and yet it is very common for UI to bleed into the world of API. I find that a developer who doesn't often ask themselves “is this for humans or machines?” is at great risk of falling into the trap of mixing them up. This happens most often with software whose users are also developers, making the distinction between the two worlds even harder.
    </p>

    <p>
        Before going more in-depth, I'll motivate my point with a few examples of the phenomenon. Some are more obvious than others, but they are all ubiquitous in the industry:
    </p>

    <ul>
        <li>
            Shell scripting
            <ul>
                <li>Shells are made for humans, but shell scripting is at the core of many systems today;</li>
            </ul>
        </li>
        <li>
            URLs
            <ul>
                <li>Something that could be typed by humans is now a part of many APIs;</li>
                <li>Must be printable, therefore requiring escaping and encoding;</li>
            </ul>
        </li>
        <li>
            HTML
            <ul>
                <li>Once a way to manually write rich text, now dynamically generated by machines;</li>
                <li>Very inneficient</li>
                <li>Must escape content to not conflict with HTML tags and to prevent malicious injection;</li>
                <li>Browsers have to evaluate human-readable strings into widgets;</li>
            </ul>
        </li>
        <li>
            SQL
            <ul>
                <li>A decent UI to explore databases is also used as the (still human readable) protocol that machines must speak to each other;</li>
                <li>Like HTML, it's a prime target for malicious injection;</li>
            </ul>
        </li>
        <li>
            Most scripting languages
            <ul>
                <li>Quick and easy to write, no explicit typing information</li>
                <li>Overly permissive, with aggressive coercion and/or casting of values</li>
                <li></li>
            </ul>
        </li>
        <li>And really any text-based format or protocol, like JSON, YAML, XML, HTTP, etc</li>
    </ul>

    <p>
        To help prevent further contamination of APIs with UI concepts, I find it useful to explore  the differences between them, highlighting their constraints and goals.
    </p>

    <h3>Argument Types</h3>

    <p>
        UI operates under the limitation that inputs and outputs must be human-readable and human “writable” (often just typable on a keyboard). An API, on the other hand, can take and produce any kind of data, and dealing with human readable data is often inefficient (as it requires parsing) or even damaging (as, say, floats are converted to and from decimal short ascii strings).
    </p>
    <p>
        This can be seen in, say, an API that takes a hostname as a string instead of an IPV4 address as an array of 4 bytes. Interestingly, the former has multiple levels of UI convenience bleeding into the API; the hostname is easier to type and easier to remember, plus it has to be DNS-resolved, which further depends on global, error-prone configuration, making it even less appropriate as an API.
    </p>

    <h3>Argument Collecting</h3>
    <p>
        Humans can't be expected to produce all arguments required for an operation at once, so UI's will guide users, step-by-step, into producing multiple arguments, which are then collected and used to execute some functionality. Machines, on the other hand, can collect as many arguments as needed before calling a function, and in fact it is much clearer for a developer to have functions explicitly require all their parameters upfront instead of relying on implicit arguments coming from some other source.
    </p>
    <p>
        An example of this kind of UI bleedover is authentication; It is natural to have authentication information as an implicit, global value when humans are operating a system. On the other hand, an API that does not explicitly specifies credentials as an argument is confusing and error prone, yet very common (e.g.: cookies, tokens in environment variables or config files)
    </p>

    <h3>Error Handling</h3>
    <p>
        Errors in UI usage happen in front of a human, and therefore can be immediately corrected and retried. In fact, errors in UI usage are expected, and good UIs will try very hard to either interpret the inputs permissively or help the human fix the error. Errors in API usage, on the other hand, happen far away from the developer (in time and space) and are software defects that can't be immediately corrected.
    </p>
    <p>
        I wonder if failing to distinguish these modes of usage was one of the motivations behind “throwing exceptions” in some programming languages; uncaught exceptions don't necessarily crash a program and are easy to debug when they happen in front of the developer (like UI errors), but are unproductive as part of APIs as they make failure states that should have been prevented in development time less obvious. Similarly, APIs that return overly friendly error messages instead of enforcing correct usage through its arguments are behaving less like good APIs and more as an IDE to developers (so, UI again).
    </p>
</body>
</html>
